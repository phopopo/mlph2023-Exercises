{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Classifier Reweighting \n",
    "\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_LO = np.load(\"data09/ttbarj_LO.npy\")\n",
    "data_NLO = np.load(\"data09/ttbarj_NLO.npy\")\n",
    "print(data_LO.shape, data_NLO.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine LO and NLO into one array and shuffle it\n",
    "data = np.concatenate((data_LO, data_NLO), axis=0)\n",
    "labels = np.concatenate((np.zeros(data_LO.shape[0]), np.ones(data_NLO.shape[0])), axis=0)\n",
    "idx = np.random.permutation(len(data))\n",
    "data = data[idx,:]\n",
    "labels=labels[idx,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(event, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        mean = event.mean(axis=0, keepdims=True)\n",
    "        std = event.std(axis=0, keepdims=True)\n",
    "    event = (event - mean) / std\n",
    "    return event, mean, std\n",
    "\n",
    "def create_dataloader(data, labels, batchsize, shuffle, mean=None, std=None):\n",
    "    data, mean, std = preprocess(data, mean, std)\n",
    "    data = torch.tensor(data).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    loader = DataLoader(TensorDataset(data, labels), batch_size=batchsize, shuffle=shuffle)\n",
    "    return loader, mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validation and test sets and create dataloaders\n",
    "n1, n2 = 50000, 60000\n",
    "batchsize = 512\n",
    "data_trn, data_val, data_tst = data[:n1,:], data[n1:n2,:], data[n2:,:]\n",
    "labels_trn, labels_val, labels_tst = labels[:n1,:], labels[n1:n2,:], labels[n2:,:]\n",
    "\n",
    "mean, std = None, None\n",
    "loader_trn, mean, std = create_dataloader(data_trn, labels_trn, batchsize, True, mean=mean, std=std)\n",
    "loader_tst, mean, std = create_dataloader(data_tst, labels_tst, batchsize, False, mean=mean, std=std)\n",
    "loader_val, mean, std = create_dataloader(data_val, labels_val, batchsize, False, mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate classifier on test set. \n",
    "# Visualize the classifier score. Compute ROC curve and AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute weights of events in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt(particle):\n",
    "    return np.sqrt(particle[:,1]**2 + particle[:,2]**2)\n",
    "def get_mass(particle):\n",
    "    return np.sqrt(particle[:,0]**2 - np.sum(particle[:,1:]**2, axis=-1))\n",
    "def get_top1(event):\n",
    "    return event[:,:4] + event[:,4:8] + event[:,8:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize transverse momentum (pt) and mass of the leading \n",
    "# top quark, using the functions defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Event Generation with a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data to folder data09\n",
    "# this might take some time (50MB)\n",
    "# you can also do this manually (download + unpack zip)\n",
    "import os, sys\n",
    "import wget\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "\n",
    "DESTINATION = \"data09\"\n",
    "url = \"https://www.thphys.uni-heidelberg.de/~plehn/pics/\"\n",
    "filename = \"tutorial-11-data.zip\"\n",
    "url = url + filename\n",
    "\n",
    "os.makedirs(DESTINATION, exist_ok=True)\n",
    "os.chdir(DESTINATION)\n",
    "wget.download(url, filename)\n",
    "with ZipFile(filename, \"r\") as zip_ref:\n",
    "    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):\n",
    "        zip_ref.extract(member=file)\n",
    "os.chdir(\"..\")\n",
    "%ls data09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1384081, 8) (296588, 8) (296588, 8)\n"
     ]
    }
   ],
   "source": [
    "data_trn = np.load(\"data09/tutorial-11-data/dy_trn_data.npy\")\n",
    "data_tst = np.load(\"data09/tutorial-11-data/dy_tst_data.npy\")\n",
    "data_val = np.load(\"data09/tutorial-11-data/dy_val_data.npy\")\n",
    "print(data_trn.shape, data_tst.shape, data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for collider kinematics\n",
    "# used for plotting and the extended preprocessing in part (d)\n",
    "def get_mass(particle):\n",
    "    return np.sqrt(np.clip(particle[:,0]**2 - np.sum(particle[:,1:]**2, axis=-1), 0, None))\n",
    "\n",
    "def get_pt(particle):\n",
    "    return np.sqrt(particle[:,1]**2 + particle[:,2]**2)\n",
    "\n",
    "def get_eta(particle):\n",
    "    p_absolute = np.sqrt(np.sum(particle[:,1:]**2, axis=-1))\n",
    "    return np.arctanh(particle[:,3] / p_absolute)\n",
    "\n",
    "def get_phi(particle):\n",
    "    return np.arctan2(particle[:,2], particle[:,1])\n",
    "\n",
    "def get_pt_phi_eta_mass(particle):\n",
    "    pt = get_pt(particle)\n",
    "    phi = get_phi(particle)\n",
    "    eta = get_eta(particle)\n",
    "    mass = get_mass(particle)\n",
    "    return np.stack((pt, phi, eta, mass), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Minimal preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct and train VAE\n",
    "# Test different bottleneck sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plotting\n",
    "# takes two sets of events (truth/train, generated) \n",
    "# of shape (n, 28) as input\n",
    "components_Eppp = [\"E [GeV]\", \"px [GeV]\", \"py [GeV]\", \"pz [GeV]\"]\n",
    "components_jetcoordinates = [\"pt [GeV]\", \"phi\", \"eta\", \"mass [GeV]\"]\n",
    "def plot(truth, generated, bins=20):\n",
    "    fig, axs = plt.subplots(4,4, figsize=(15,15))\n",
    "    \n",
    "    # plot (E, px, py, pz) for both particles\n",
    "    for iparticle in range(2):\n",
    "        for icomponent in range(4):\n",
    "            ax = axs[iparticle, icomponent]\n",
    "            xlabel = f\"{components_Eppp[icomponent]} of particle {iparticle+1}\"\n",
    "            i = iparticle*4 + icomponent\n",
    "            \n",
    "            bins_local = bins\n",
    "            _, bins_local, _ = ax.hist(truth[:,i], bins=bins_local, alpha=.5, label=\"truth\", density=True)\n",
    "            ax.hist(generated[:,i], bins=bins_local, alpha=.5, label=\"model\", density=True)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(xlabel)\n",
    "    \n",
    "    # plot (pt phi eta mass) for both particles\n",
    "    truth = np.concatenate((get_pt_phi_eta_mass(truth[:,:4]), \n",
    "                            get_pt_phi_eta_mass(truth[:,4:])), axis=-1)\n",
    "    generated = np.concatenate((get_pt_phi_eta_mass(generated[:,:4]), \n",
    "                                get_pt_phi_eta_mass(generated[:,4:])), axis=-1)\n",
    "    for iparticle in range(2):\n",
    "        for icomponent in range(4):\n",
    "            ax = axs[2+iparticle, icomponent]\n",
    "            xlabel = f\"{components_jetcoordinates[icomponent]} of particle {iparticle+1}\"\n",
    "            i = iparticle*4 + icomponent\n",
    "            \n",
    "            bins_local = bins\n",
    "            _, bins_local, _ = ax.hist(truth[:,i], bins=bins_local, alpha=.5, label=\"truth\", density=True)\n",
    "            ax.hist(generated[:,i], bins=bins_local, alpha=.5, label=\"model\", density=True)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(xlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test mass and momentum conservation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuts in the dataset\n",
    "get_pt(data_tst[:,:4]).min(), get_pt(data_tst[:,4:]).min() # pt cuts\n",
    "get_eta(data_tst[:,:4]).min(), get_eta(data_tst[:,:4]).max()\n",
    "\n",
    "eta_cut = 2.5 + 1e-5 # should be 2.5 but one event is weird\n",
    "pt_cut = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(events, mean=None, std=None):\n",
    "    particle1, particle2 = events[:,:4], events[:,4:]\n",
    "    events_jetcoordinates = np.stack((get_pt(particle1), get_phi(particle1), get_eta(particle1), get_mass(particle1), get_pt(particle2), get_phi(particle2), get_eta(particle2), get_mass(particle2)), axis=-1)\n",
    "    events_reduced = events_jetcoordinates[:,[0,2,6]]\n",
    "    \n",
    "    events_reduced[:,0] = np.log(events_reduced[:,0] - pt_cut)\n",
    "    events_reduced[:,1:] = np.arctanh(events_reduced[:,1:] / eta_cut)\n",
    "    \n",
    "    if mean is None or std is None:\n",
    "        mean = events_reduced.mean(axis=0)\n",
    "        std = events_reduced.std(axis=0)\n",
    "    events_reduced = (events_reduced - mean) / std\n",
    "    \n",
    "    assert np.isfinite(events_reduced).all()\n",
    "    return events_reduced, mean, std\n",
    "    \n",
    "def undo_preprocess2(events_reduced, mean, std):\n",
    "    events_reduced = events_reduced * std + mean\n",
    "    \n",
    "    events_reduced[:,0] = np.exp(events_reduced[:,0]) + pt_cut\n",
    "    events_reduced[:,[1,2]] = np.tanh(events_reduced[:,[1,2]]) * eta_cut\n",
    "    \n",
    "    pt1, eta1, eta2 = events_reduced.T\n",
    "    phi1 = np.random.uniform(0, 2*np.pi, events_reduced.shape[0])\n",
    "    mass1, mass2 = np.ones((2, events_reduced.shape[0])) * 0.105\n",
    "    px1 = pt1 * np.cos(phi1)\n",
    "    py1 = pt1 * np.sin(phi1)\n",
    "    pz1 = pt1 * np.sinh(eta1)\n",
    "    e1 = np.sqrt(mass1**2 + px1**2 + py1**2 + pz1**2)\n",
    "    px2 = -px1\n",
    "    py2 = -py1\n",
    "    pt2 = pt1\n",
    "    pz2 = pt2 * np.sinh(eta2)\n",
    "    e2 = np.sqrt(mass2**2 + px2**2 + py2**2 + pz2**2)\n",
    "    return np.stack((e1, px1, py1, pz1, e2, px2, py2, pz2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train VAE on dataset with extended preprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
