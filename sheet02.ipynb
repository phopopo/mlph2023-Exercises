{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Trees and Random Forests\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "pts = np.load('data02/data1d.npy')\n",
    "labels = np.load('data02/labels1d.npy')\n",
    "\n",
    "# TODO: Sort the points to easily split them\n",
    "idx = np.argsort(pts)\n",
    "sorted_pts=pts[idx]\n",
    "labels = labels[idx]\n",
    "N_tot = len(pts)\n",
    "\n",
    "# TODO: Implement or find implementation for Gini impurity, entropy and misclassifcation rate\n",
    "def gini(p):\n",
    "    #Compute the gini impurity. Each element of p is the probability that a new thing gets sorted to class i. In this case, there are only two classes\n",
    "    return 1 - sum(p**2)\n",
    "\n",
    "def H(p):\n",
    "    #Computes the entropy\n",
    "    return -sum(p *log(p))\n",
    "\n",
    "# TODO: Iterate over the possible splits, evaulating and saving the three criteria for each one\n",
    "Ginis = np.zeros(N_tot-1)\n",
    "Infogains = np.zeros(N_tot-1)\n",
    "misclassrates = np.zeros(N_tot-1)\n",
    "\n",
    "\n",
    "for i in range(1,N_tot):\n",
    "    #create an array that represents the splits with 0 and 1\n",
    "    nodes = np.zeros(N_tot)\n",
    "    nodes[i:] = 1\n",
    "    #calculate the probabilities for the classes 0 and 1\n",
    "    p = np.array([(N_tot - sum(nodes))/N_tot , sum(nodes)/N_tot])\n",
    "\n",
    "    #calculate the gini impurity:\n",
    "    Ginis[i-1] = gini(p)\n",
    "    #calculate the information gain:\n",
    "    \n",
    "    \n",
    "# TODO: Compute the split that each criterion favours and visualize them \n",
    "#       (e.g. with a histogram for each class and vertical lines to show the splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1833, 116)\n",
      "(116, 1833)\n"
     ]
    }
   ],
   "source": [
    "# load the dijet data\n",
    "features = np.load('data02/dijet_features_normalized.npy')\n",
    "labels = np.load('data02/dijet_labels.npy')\n",
    "\n",
    "# TODO: define train, val and test splits as specified (make sure to shuffle the data before splitting it!)\n",
    "\n",
    "order = np.arange(len(labels))\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(order)\n",
    "features = features[:, order]\n",
    "labels = labels[order]\n",
    "train_features, val_features, test_features = features[:, :-400], features[:, -400:-200], features[:, -200:]\n",
    "train_labels, val_labels, test_labels = labels[:-400], labels[-400:-200], labels[-200:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "20\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train a random forest classifier for each combination of hyperparameters as specified on the sheet\n",
    "#       and evaluate the performances on the validation set.\n",
    "estimators = []\n",
    "fits = []\n",
    "scores = []\n",
    "\n",
    "\n",
    "for n_trees in [5, 10, 20, 100]:\n",
    "    for crit in [\"gini\", \"entropy\"]:\n",
    "        for dep in [2, 5, 10, None]:\n",
    "            clf = RandomForestClassifier(n_estimators=n_trees, criterion=crit,max_depth=dep)\n",
    "            \n",
    "            fits.append(clf.fit(train_features.T, train_labels))\n",
    "            scores.append(clf.score(val_features.T, val_labels))\n",
    "            estimators.append(clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.735,\n",
       " 0.715,\n",
       " 0.72,\n",
       " 0.685,\n",
       " 0.68,\n",
       " 0.725,\n",
       " 0.715,\n",
       " 0.67,\n",
       " 0.72,\n",
       " 0.74,\n",
       " 0.775,\n",
       " 0.705,\n",
       " 0.71,\n",
       " 0.77,\n",
       " 0.77,\n",
       " 0.74,\n",
       " 0.72,\n",
       " 0.74,\n",
       " 0.74,\n",
       " 0.75,\n",
       " 0.725,\n",
       " 0.75,\n",
       " 0.76,\n",
       " 0.75,\n",
       " 0.72,\n",
       " 0.76,\n",
       " 0.755,\n",
       " 0.77,\n",
       " 0.73,\n",
       " 0.745,\n",
       " 0.75,\n",
       " 0.765]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: for your preferred configuration, evaluate the performance of the best configuration on the test set\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Fits\n",
    "\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "data_Vm, data_p = np.load(\"data02/gas.npy\")\n",
    "\n",
    "# TODO: Implement the ideal gas law\n",
    "\n",
    "# TODO: Implement the negative log-likelihood\n",
    "\n",
    "# TODO: Perform the fit, print the results\n",
    "\n",
    "# TODO: Visualize your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the real gas law\n",
    "\n",
    "# TODO: Implement the negative log-likelihood\n",
    "\n",
    "# TODO: Perform the fit, print the results\n",
    "\n",
    "# TODO: Visualize your results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
